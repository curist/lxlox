let lib = import "src/lib.lx"
let types = import "src/types.lx"
let initScanner = import "src/scanner.lx"
let object = import "src/object.lx"

let TOKEN = types.TOKEN
let OP = types.OP
let ValueType = types.ValueType
let ObjType = object.ObjType

let mod = {}

let PREC = {
  let iota = lib.iota(0)
  {
    NONE:       iota(),
    ASSIGNMENT: iota(),  // =
    OR: iota(),          // or
    AND: iota(),         // and
    EQUALITY: iota(),    // == !=
    COMPARISON: iota(),  // < > <= >=
    TERM: iota(),        // + -
    FACTOR: iota(),      // * /
    UNARY: iota(),       // ! -
    CALL: iota(),        // . ()
    PRIMARY: iota(),
    // XXX: what about [] index access pattern?
    // how do we resolve conflict between hashmap & block?
  }
}

fn Value(kind, value) {{
  kind: kind,
  value: value,
}}

fn BOOL_VAL(value)   { Value(ValueType.BOOL, value) }
fn NIL_VAL(value)    { Value(ValueType.NIL, nil) }
// XXX: ^ not sure if we need these two
fn NUMBER_VAL(value) { Value(ValueType.NUMBER, value) }
fn OBJ_VAL(value)    { Value(ValueType.OBJ, value) }

fn ObjectString(string) { OBJ_VAL(object.ObjectString(string)) }

let pp = lib.pp

mod.debugPrint = fn(src) {
  let scanner = initScanner(src)

  let line = -1

  for true {
    let token = scanner.scanToken()

    let lineInfo = if token.line != line {
      lib.padStart(token.line, 4, " ")
    } else {
      "   | "
    }
    pp([
      lineInfo,
      " ", token.type, " ",
      lib.padRight(token.lexeme, 30, " "),
      "\t| ",
      types.TOKEN_NAME[token.type],
    ])

    if token.type == types.TOKEN.EOF {
      break
    }
  }
}

mod.compile = fn(src, filename) {
  let scanner = initScanner(src)

  // XXX: future
  // TODO: put line info as debug info, as part of the bin format
  let line = -1

  // to get around mutual references
  let parseRules
  let getRule

  let chunks = [{
    filename: filename,
    bytecode: [],
    constants: [],
    lines: [],
  }]

  let parser = {
    current: 0,
    previous: 0,
    hadError: false,
    panicMode: false,
  }

  fn currentChunk() {
    // XXX: probably will need to change this later
    // Right now, the chunk pointer is stored in a module-level variable,
    // like we store other global state.
    // Later, when we start compiling user-defined functions,
    // the notion of “current chunk” gets more complicated.
    // To avoid having to go back and change a lot of code,
    // I encapsulate that logic in the currentChunk() function.
    // ^ from book text
    // https://craftinginterpreters.com/compiling-expressions.html#emitting-bytecode
    chunks[len(chunks) - 1]
  }

  fn emitByte(byte, line) {
    let chunk = currentChunk()
    chunk.bytecode = append(chunk.bytecode, lib.tohex(byte))
    chunk.lines = append(chunk.lines, line)
  }

  fn emitBytes(byte1, byte2, line) {
    emitByte(byte1, line)
    emitByte(byte2, line)
  }

  let constantsCache = {}

  fn calcValueKey(value) {
    let k = str(value.kind) + ":"
    if value.kind == ValueType.NUMBER {
      k = k + str(value.value)
    } else if value.kind == ValueType.OBJ {
      let obj = value.value
      k = k + str(obj.kind) + ":"
      if obj.kind == ObjType.STRING {
        k = k + obj.value
      } else {
        error("Invalid object type: " + str(obj.kind))
      }

    } else {
      // currently only BOOL & NIL is in the category
      // and...they won't be stored in constants
    }
    return k
  }

  fn addConstant(chunk, value) {
    let k = calcValueKey(value)
    let index = constantsCache[k]
    if index { return index }
    chunk.constants = append(chunk.constants, value)
    index = len(chunk.constants) - 1
    constantsCache[k] = index
    return index
  }

  fn makeConstant(value) {
    let constant = addConstant(currentChunk(), value)
    if constant > 256 {
      error("Too many constants in one chunk.")
      return 0
    }
    return constant
  }

  fn emitConstant(value, line) {
    emitBytes(OP.CONSTANT, makeConstant(value), line)
  }

  fn errorAt(token, message) {
    if parser.panicMode {
      return
    }
    parser.panicMode = true
    pp([
      "[line ", token.line, "]",
      if token.type == TOKEN.EOF {
        " at end"
      } else if token.type == TOKEN.ERROR {
        ""
      } else {
        " at '" + token.lexeme + "'"
      },
      ": ", message,
    ])
    parser.hadError = true
  }

  fn error(message) {
    errorAt(parser.previous, message)
  }

  fn errorAtCurrent(message) {
    errorAt(parser.current, message)
  }

  fn advance() {
    parser.previous = parser.current
    for true {
      parser.current = scanner.scanToken()
      if parser.current.type != TOKEN.ERROR {
        break
      }
      errorAtCurrent(parser.current.lexeme)
    }
  }

  fn consume(type, message) {
    if parser.current.type == type {
      advance()
      return
    }
    errorAtCurrent(message)
  }

  fn check(type) { parser.current.type == type }

  fn match(type) {
    if !check(type) {return false}
    advance()
    true
  }

  fn emitReturn() {
    emitByte(OP.RETURN, parser.previous.line)
  }

  fn parsePrecedence(precedence) {
    advance()
    let prefixRule = getRule(parser.previous.type).prefix
    if !prefixRule {
      error("Expect expression.")
      return
    }

    let canAssign = precedence <= PREC.ASSIGNMENT
    prefixRule(canAssign)

    for precedence <= getRule(parser.current.type).precedence {
      advance()
      let infixRule = getRule(parser.previous.type).infix
      // XXX: should we really error out here?
      if !infixRule {
        error("Expect expression.")
        return
      }
      infixRule(canAssign)
    }

    if canAssign and match(TOKEN.EQUAL) {
      error("Invalid assignment target.")
    }
  }

  fn identifierConstant(nameToken) {
    makeConstant(ObjectString(nameToken.lexeme))
  }

  fn parseVariable(errorMessage) {
    consume(TOKEN.IDENTIFIER, errorMessage)
    identifierConstant(parser.previous)
  }

  fn defineVariable(global, line) {
    emitBytes(OP.DEFINE_GLOBAL, global, line)
  }

  fn endCompiler() {
    emitReturn()
  }

  fn binary(canAssign) {
    let operatorType = parser.previous.type
    let line = parser.previous.line
    let rule = getRule(operatorType)
    parsePrecedence(rule.precedence + 1)

    let opCodes = {
      [TOKEN.BANG_EQUAL]:    [OP.EQUAL, OP.NOT],
      [TOKEN.EQUAL_EQUAL]:    OP.EQUAL,
      [TOKEN.GREATER]:        OP.GREATER,
      [TOKEN.GREATER_EQUAL]: [OP.LESS, OP.NOT],
      [TOKEN.LESS]:           OP.LESS,
      [TOKEN.LESS_EQUAL]:    [OP.GREATER, OP.NOT],
      [TOKEN.PLUS]:           OP.ADD,
      [TOKEN.MINUS]:          OP.SUBTRACT,
      [TOKEN.STAR]:           OP.MULTIPLY,
      [TOKEN.SLASH]:          OP.DIVIDE,
      [TOKEN.MOD]:            OP.MOD,
    }
    let codes = opCodes[operatorType]
    if codes {
      if type(codes) == "array" {
        emitBytes(codes[0], codes[1], line)
      } else {
        emitByte(codes, line)
      }
    } else {
      // unreable, supposely
      error("bad binary op: " + types.TOKEN_NAME[operatorType])
    }
  }

  fn literal(canAssign) {
    let operatorType = parser.previous.type

    let opCodes = {
      [TOKEN.FALSE]: OP.FALSE,
      [TOKEN.NIL]: OP.NIL,
      [TOKEN.TRUE]: OP.TRUE,
    }
    let opCode = opCodes[operatorType]
    if opCode {
      emitByte(opCode, parser.previous.line)
    } else {
      // unreable, supposely
      error("bad literal op: " + types.TOKEN_NAME[operatorType])
    }
  }

  fn expression() {
    parsePrecedence(PREC.ASSIGNMENT)
  }

  fn letExpression() {
    let line = parser.current.line
    let global = parseVariable("Expect variable name.")
    if match(TOKEN.EQUAL) {
      expression()
    } else {
      emiteByte(OP.NIL, line)
    }
    defineVariable(global, line)
    emitBytes(OP.CONSTANT, global, line)
  }

  fn synchronize() {
    parser.panicMode = false
    for parser.current.type != TOKEN.EOF {
      let breakpoints = {
        [TOKEN.FN]: true,
        [TOKEN.LET]: true,
        [TOKEN.FOR]: true,
        [TOKEN.IF]: true,
        [TOKEN.RETURN]: true,
        [TOKEN.DEFER]: true,
        [TOKEN.IMPORT]: true,
      }
      if breakpoints[parser.current.type] {
        return
      }
      advance()
    }
  }

  fn expressionStatement() {
    let line = parser.current.line

    if match(TOKEN.LET) {
      letExpression()
    } else {
      expression()
    }

    if parser.panicMode {
      synchronize()
    } else {
      emitByte(OP.POP, line)
      // XXX: let's just pop it for now
      // when we get to block scope, we will figure out
      // how to implicitly return last evaluated expression
    }
  }

  fn grouping(canAssign) {
    expression()
    consume(TOKEN.RIGHT_PAREN, "Expect ')' after expression.")
  }

  fn number(canAssign) {
    let value = parser.previous.literal
    let line = parser.previous.line
    if value >= 0 and value < 256 {
      emitBytes(OP.CONST_BYTE, value, line)
    } else {
      emitConstant(NUMBER_VAL(value), line)
    }
  }

  fn string(canAssign) {
    let line = parser.previous.line
    emitConstant(ObjectString(parser.previous.literal), line)
  }

  fn namedVariable(nameToken, canAssign) {
    let line = parser.current.line
    let nameConstIndex = identifierConstant(nameToken)
    if canAssign and match(TOKEN.EQUAL) {
      expression()
      emitBytes(OP.SET_GLOBAL, nameConstIndex, line)
    } else {
      emitBytes(OP.GET_GLOBAL, nameConstIndex, line)
    }
  }

  fn variable(canAssign) {
    namedVariable(parser.previous, canAssign)
  }

  fn unary(canAssign) {
    let opType = parser.previous.type
    let line = parser.previous.line

    parsePrecedence(PREC.UNARY)

    let opCodes = {
      [TOKEN.BANG]: OP.NOT,
      [TOKEN.MINUS]: OP.NEGATE,
    }
    let opCode = opCodes[opType]
    if opCode {
      emitByte(opCode, line)
    } else {
      // unreable, supposely
      error("bad unary op: " + types.TOKEN_NAME[opType])
    }
  }

  parseRules = {
    [TOKEN.LEFT_PAREN]    : [grouping, nil,    PREC.NONE],
    [TOKEN.RIGHT_PAREN]   : [nil,      nil,    PREC.NONE],
    [TOKEN.LEFT_BRACE]    : [nil,      nil,    PREC.NONE], 
    [TOKEN.RIGHT_BRACE]   : [nil,      nil,    PREC.NONE],
    [TOKEN.LEFT_BRACKET]  : [nil,      nil,    PREC.NONE], 
    [TOKEN.RIGHT_BRACKET] : [nil,      nil,    PREC.NONE],
    [TOKEN.COMMA]         : [nil,      nil,    PREC.NONE],
    [TOKEN.DOT]           : [nil,      nil,    PREC.NONE],
    [TOKEN.MINUS]         : [unary,    binary, PREC.TERM],
    [TOKEN.PLUS]          : [nil,      binary, PREC.TERM],
    [TOKEN.SEMICOLON]     : [nil,      nil,    PREC.NONE],
    [TOKEN.SLASH]         : [nil,      binary, PREC.FACTOR],
    [TOKEN.STAR]          : [nil,      binary, PREC.FACTOR],
    [TOKEN.MOD]           : [nil,      binary, PREC.FACTOR],
    [TOKEN.BANG]          : [unary,    nil,    PREC.NONE],
    [TOKEN.BANG_EQUAL]    : [nil,      binary, PREC.EQUALITY],
    [TOKEN.EQUAL]         : [nil,      nil,    PREC.NONE],
    [TOKEN.EQUAL_EQUAL]   : [nil,      binary, PREC.EQUALITY],
    [TOKEN.GREATER]       : [nil,      binary, PREC.COMPARISON],
    [TOKEN.GREATER_EQUAL] : [nil,      binary, PREC.COMPARISON],
    [TOKEN.LESS]          : [nil,      binary, PREC.COMPARISON],
    [TOKEN.LESS_EQUAL]    : [nil,      binary, PREC.COMPARISON],
    [TOKEN.IDENTIFIER]    : [variable, nil,    PREC.NONE],
    [TOKEN.STRING]        : [string,   nil,    PREC.NONE],
    [TOKEN.NUMBER]        : [number    nil,    PREC.NONE],
    [TOKEN.AND]           : [nil,      nil,    PREC.NONE],
    [TOKEN.ELSE]          : [nil,      nil,    PREC.NONE],
    [TOKEN.FALSE]         : [literal,  nil,    PREC.NONE],
    [TOKEN.FOR]           : [nil,      nil,    PREC.NONE],
    [TOKEN.FN]            : [nil,      nil,    PREC.NONE],
    [TOKEN.IF]            : [nil,      nil,    PREC.NONE],
    [TOKEN.NIL]           : [literal,  nil,    PREC.NONE],
    [TOKEN.OR]            : [nil,      nil,    PREC.NONE],
    [TOKEN.DEFER]         : [nil,      nil,    PREC.NONE],
    [TOKEN.RETURN]        : [nil,      nil,    PREC.NONE],
    [TOKEN.BREAK]         : [nil,      nil,    PREC.NONE],
    [TOKEN.TRUE]          : [literal,  nil,    PREC.NONE],
    [TOKEN.LET]           : [nil,      nil,    PREC.NONE],
    [TOKEN.ERROR]         : [nil,      nil,    PREC.NONE],
    [TOKEN.EOF]           : [nil,      nil,    PREC.NONE],
  }

  getRule = fn(type) {
    let rule = parseRules[type]
    return {
      prefix: rule[0],
      infix: rule[1],
      precedence: rule[2],
    }
  }

  advance()
  for !match(TOKEN.EOF) {
    expressionStatement()
  }
  consume(TOKEN.EOF, "Expect end of expression.")
  endCompiler()

  return {
    success: !parser.hadError,
    chunks: chunks,
  }
}

mod
